
# API de Despliegue de Modelo de Machine Learning con FastAPI

Este proyecto implementa una API RESTful utilizando FastAPI para el despliegue del modelo de machine learning sobre  la renegociaci√≥n de deudas.

## Tabla de Contenidos  
- [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [Dockerizaci√≥n](#dockerizaci√≥n)
- [Despliegue en Kubernetes](#despliegue-en-kubernetes)
- [Contribuciones](#contribuciones)
- [Licencia](#licencia)

## Descripci√≥n del Proyecto

Este proyecto implementa un modelo de √°rbol de decisi√≥n para la evaluaci√≥n de propuestas de renegociaci√≥n de deudas. El sistema analiza m√∫ltiples variables relacionadas con el perfil del deudor y su comportamiento crediticio para determinar la viabilidad de aceptar una propuesta de renegociaci√≥n, generando un resultado binario que indica la aprobaci√≥n (1) o rechazo (0) de la solicitud.
Puedes ver la implementaci√≥n del modelo en [Notebook](notebooks/analisis-de-clientes-bancarios.ipynb "Notebook de an√°lisis")


### Variables de Entrada del Modelo
El √°rbol de decisi√≥n eval√∫a los siguientes atributos para cada caso:

* ABONO_OFERTADO: Monto propuesto como pago inicial (ej. 53000)
* CONSUMO_SBIF: Indicador de consumo reportado al regulador financiero (ej. 9603)
* EDAD: Edad del deudor (ej. 31)
* SEXO_BIN: Indicador binario de g√©nero (1: masculino, 0: femenino)
* SCORE: Puntuaci√≥n crediticia del cliente (ej. 378)
* DEUDA_PROM3: Deuda promedio de los √∫ltimos 3 meses (ej. 992387)
* PROME_UTILIZACION_3MESES: Ratio de utilizaci√≥n de cr√©dito (0-1)
* PROME_LINEA_CREDITO_3MESES: Promedio de l√≠nea de cr√©dito disponible (ej. 594)
* PROME_CANT_INSTITUTO_3MESES: N√∫mero promedio de instituciones financieras con las que mantiene deuda (ej. 3)
* SUMA_MOROSA_3MESES: Suma de d√≠as en mora en los √∫ltimos 3 meses (ej. 436)
* Deuda_Char_008: Indicador binario de caracterizaci√≥n de deuda (1: cumple condici√≥n, 0: no cumple)
* Pago_Char_008: Indicador binario de comportamiento de pago (1: cumple condici√≥n, 0: no cumple)

### Variable de Salida
Resultado binario:
* 1: Aprobar la propuesta de renegociaci√≥n
* 0: Rechazar la propuesta de renegociaci√≥n

###  Caracter√≠sticas principales

* Implementaci√≥n de √°rbol de decisi√≥n para clasificaci√≥n binaria
* Evaluaci√≥n automatizada basada en reglas derivadas del an√°lisis de datos hist√≥ricos
* Alta interpretabilidad de las decisiones a trav√©s de la estructura del √°rbol
* Capacidad de predecir la probabilidad de √©xito de una renegociaci√≥n

## Requisitos
- Python 3.11+
- FastAPI
- Uvicorn
- Pydantic
- Dependencias espec√≠ficas del modelo (scikit-learn, TensorFlow, PyTorch, etc.)


## Estructura del Proyecto

La estructura del proyecto es la siguiente:

```
serving-ml-app/
‚îú‚îÄ‚îÄ .github/
‚îú‚îÄ‚îÄ cloudformation/
‚îú‚îÄ‚îÄ container/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ .containerignore
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .python-version
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ poetry.lock
‚îî‚îÄ‚îÄ pyproject.toml
```

## Instalaci√≥n

Para ejecutar este proyecto localmente, sigue estos pasos:

1. Clonar el repositorio:

```bash
git clone https://github.com/ecaminero/serving-ml-app.git
cd serving-ml-app
```

2. Crear y activar un entorno virtual:

```bash
# En Windows
.\venv\Scripts\activate

# En Linux o macOS
source venv/bin/activate
```

3. Instalar las dependencias:

Este proyecto utiliza [Poetry](https://python-poetry.org/) para la gesti√≥n de dependencias:

```bash
poetry install
```

> **¬øUsas Windows y ves un error como este?**
> ```
> Current Python version (3.10.10) is not allowed by the project (^3.11)
> ```
> Eso significa que tu sistema tiene otra versi√≥n de Python activa.  
> Puedes solucionarlo usando la ruta donde tengas instalado Python 3.11:
>
> ```bash
> poetry env use C:\ruta\a\python311.exe
> ```
>
> Para saber qu√© rutas tienes disponibles, ejecuta en la consola:
> ```bash
> where python
> ```
> Luego copia la ruta que corresponde a tu Python 3.11 e ins√©rtala en el comando anterior.

## Uso

Para iniciar la API localmente:

1. Aseg√∫rate de estar en la ra√≠z del proyecto (donde est√° el archivo `pyproject.toml`)

2. Ejecuta la aplicaci√≥n con:

```bash
poetry run fastapi dev src/main.py
```

La API estar√° disponible en `http://127.0.0.1:8000`.
---

## Prueba de la API

> Este proyecto cuenta con **dos endpoints `/predict` diferentes**, uno para texto libre (modelo NLP) y otro para datos num√©ricos (modelo estructurado). A continuaci√≥n se describen ambos.

---

### Prueba del modelo

Mientras el servidor est√© corriendo (`uvicorn src.main:app --reload`), no podr√°s escribir en esa terminal.

Abre una **nueva ventana de consola (CMD o PowerShell)** para ejecutar el siguiente comando:

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "ABONO_OFERTADO": 53000,
    "CONSUMO_SBIF": 9603,
    "EDAD": 31,
    "SEXO_BIN": 1,
    "SCORE": 378,
    "DEUDA_PROM3": 992387,
    "PROME_UTILIZACION_3MESES": 1,
    "PROME_LINEA_CREDITO_3MESES": 594,
    "PROME_CANT_INSTITUTO_3MESES": 3,
    "SUMA_MOROSA_3MESES": 436,
    "Deuda_Char_008": 1,
    "Pago_Char_008": 0
  }'
```

Una vez ejecutado, deber√≠as ver una respuesta similar a:

```json
{
    "id":"3a0d2858-1df1-11f0-a6ef-c2dc360e8a7d",
    "probabilidad":[
        0.7878787878787878, 
        0.21212121212121213
    ]
}
```
---

#### üîπ Opci√≥n 2: Desde el navegador con FastAPI Docs
![Arquitectura de la API](docs/imagen1.png "T√≠tulo opcional")

1. Abre tu navegador y visita: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
2. Haz clic en `POST /predict` y luego en **"Try it out"**
3. En el cuerpo del mensaje (`Request body`), pega este ejemplo de JSON:

```json
{
  "ABONO_OFERTADO": 53000,
  "CONSUMO_SBIF": 9603,
  "EDAD": 31,
  "SEXO_BIN": 1,
  "SCORE": 378,
  "DEUDA_PROM3": 992387,
  "PROME_UTILIZACION_3MESES": 1,
  "PROME_LINEA_CREDITO_3MESES": 594,
  "PROME_CANT_INSTITUTO_3MESES": 3,
  "SUMA_MOROSA_3MESES": 436,
  "Deuda_Char_008": 1,
  "Pago_Char_008": 0
}
```

4. Haz clic en **"Execute"**
5. La predicci√≥n aparecer√° en la secci√≥n **Response body**

## Dockerizaci√≥n

1. Construir la imagen Docker:

```bash
docker build -t serving-ml-app -f container/Dockerfile .
```

2. Ejecutar el contenedor:

```bash
docker run -p 8000:8000 serving-ml-app
```

## Arquitectura En AWS
![Arquitectura de la API](docs/fargate-arquitecture.webp "T√≠tulo opcional")



## Opcional: Despliegue en Kubernetes

![Arquitectura de la API](docs/arquitectura-api.png)

1. Crear los archivos de configuraci√≥n de Kubernetes:

- `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: serving-ml-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: serving-ml-app
  template:
    metadata:
      labels:
        app: serving-ml-app
    spec:
      containers:
      - name: serving-ml-app
        image: tu-usuario/serving-ml-app:latest
        ports:
        - containerPort: 8000
```

- `service.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: serving-ml-app
spec:
  selector:
    app: serving-ml-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```

2. Aplicar los archivos:

```bash
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
```

## Contribuciones

¬°Las contribuciones son bienvenidas! Por favor, abre un *pull request* o issue si tienes sugerencias.

## Licencia

Este proyecto est√° licenciado bajo los t√©rminos de la licencia MIT.
