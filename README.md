
# API de Despliegue de Modelo de Machine Learning con FastAPI

Este proyecto implementa una API RESTful utilizando FastAPI para el despliegue del modelo de machine learning 'multilingual-uncased-sentiment'.
Este modelo, basado en BERT, est√° optimizado para el an√°lisis de sentimientos en rese√±as de productos en seis idiomas: ingl√©s, neerland√©s, alem√°n, franc√©s, espa√±ol e italiano.
Predice la opini√≥n de la rese√±a mediante un n√∫mero de estrellas (entre 1 y 5).

## Tabla de Contenidos

- [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [Dockerizaci√≥n](#dockerizaci√≥n)
- [Despliegue en Kubernetes](#despliegue-en-kubernetes)
- [Contribuciones](#contribuciones)
- [Licencia](#licencia)

## Descripci√≥n del Proyecto

Esta API permite a los usuarios enviar texto en uno de los seis idiomas soportados y recibir una predicci√≥n del sentimiento en forma de estrellas (1 a 5).
Utiliza FastAPI para manejar las solicitudes HTTP y el modelo 'multilingual-uncased-sentiment' para el an√°lisis de sentimientos.

## Estructura del Proyecto

La estructura del proyecto es la siguiente:

```
serving-ml-app/
‚îú‚îÄ‚îÄ .github/
‚îú‚îÄ‚îÄ cloudformation/
‚îú‚îÄ‚îÄ container/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ .containerignore
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .python-version
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ poetry.lock
‚îî‚îÄ‚îÄ pyproject.toml
```

## Instalaci√≥n

Para ejecutar este proyecto localmente, sigue estos pasos:

1. Clonar el repositorio:

```bash
git clone https://github.com/ecaminero/serving-ml-app.git
cd serving-ml-app
```

2. Crear y activar un entorno virtual:

```bash
python -m venv venv

# En Windows
.\venv\Scripts\activate

# En Linux o macOS
source venv/bin/activate
```

3. Instalar las dependencias:

Este proyecto utiliza [Poetry](https://python-poetry.org/) para la gesti√≥n de dependencias:

```bash
poetry install
```

> **¬øUsas Windows y ves un error como este?**
> ```
> Current Python version (3.10.10) is not allowed by the project (^3.11)
> ```
> Eso significa que tu sistema tiene otra versi√≥n de Python activa.  
> Puedes solucionarlo usando la ruta donde tengas instalado Python 3.11:
>
> ```bash
> poetry env use C:\ruta\a\python311.exe
> ```
>
> Para saber qu√© rutas tienes disponibles, ejecuta en la consola:
> ```bash
> where python
> ```
> Luego copia la ruta que corresponde a tu Python 3.11 e ins√©rtala en el comando anterior.

## Uso

Para iniciar la API localmente:

1. Aseg√∫rate de estar en la ra√≠z del proyecto (donde est√° el archivo `pyproject.toml`)

2. Ejecuta la aplicaci√≥n con:

```bash
uvicorn src.main:app --reload
```

La API estar√° disponible en `http://127.0.0.1:8000`.

---

## Prueba de la API

> Este proyecto cuenta con **dos endpoints `/predict` diferentes**, uno para texto libre (modelo NLP) y otro para datos num√©ricos (modelo estructurado). A continuaci√≥n se describen ambos.

---

### üî∏ API 1: Prueba del modelo de an√°lisis de texto (NLP)

Mientras el servidor est√© corriendo (`uvicorn src.main:app --reload`), no podr√°s escribir en esa terminal.

Abre una **nueva ventana de consola (CMD o PowerShell)** para ejecutar el siguiente comando:

```bash
curl -X POST "http://127.0.0.1:8000/predict" -H "Content-Type: application/json" -d "{"text": "Esta es una excelente rese√±a de producto."}"
```

Una vez ejecutado, deber√≠as ver una respuesta similar a:

```json
{
  "id": "0e1d8d73-1427-11f0-9ba3-bcf4d472f72c",
  "results": {
    "0.7878787878787878": 0.21212121212121213
  }
}
```

---

### üî∏ API 2: Prueba del modelo con atributos estructurados

#### üîπ Opci√≥n 1: Desde el navegador con FastAPI Docs

1. Abre tu navegador y visita: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
2. Haz clic en `POST /predict` y luego en **"Try it out"**
3. En el cuerpo del mensaje (`Request body`), pega este ejemplo de JSON:

```json
{
  "ABONO_OFERTADO": 53000,
  "CONSUMO_SBIF": 9603,
  "EDAD": 31,
  "SEXO_BIN": 1,
  "SCORE": 378,
  "DEUDA_PROM3": 992387,
  "PROME_UTILIZACION_3MESES": 1,
  "PROME_LINEA_CREDITO_3MESES": 594,
  "PROME_CANT_INSTITUTO_3MESES": 3,
  "SUMA_MOROSA_3MESES": 436,
  "Deuda_Char_008": 1,
  "Pago_Char_008": 0
}
```

4. Haz clic en **"Execute"**
5. La predicci√≥n aparecer√° en la secci√≥n **Response body**

#### üîπ Opci√≥n 2: Desde la terminal usando curl

```bash
curl -X POST "http://127.0.0.1:8000/predict" ^
 -H "Content-Type: application/json" ^
 -d "{{\"ABONO_OFERTADO\":53000,\"CONSUMO_SBIF\":9603,\"EDAD\":31,\"SEXO_BIN\":1,\"SCORE\":378,\"DEUDA_PROM3\":992387,\"PROME_UTILIZACION_3MESES\":1,\"PROME_LINEA_CREDITO_3MESES\":594,\"PROME_CANT_INSTITUTO_3MESES\":3,\"SUMA_MOROSA_3MESES\":436,\"Deuda_Char_008\":1,\"Pago_Char_008\":0}}"
```

Esto devolver√° una respuesta JSON con la predicci√≥n del modelo.
## Dockerizaci√≥n

1. Construir la imagen Docker:

```bash
docker build -t serving-ml-app -f container/Dockerfile .
```

2. Ejecutar el contenedor:

```bash
docker run -p 8000:8000 serving-ml-app
```

![Arquitectura de la API](./arquitectura-api.png)
## Despliegue en Kubernetes

1. Crear los archivos de configuraci√≥n de Kubernetes:

- `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: serving-ml-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: serving-ml-app
  template:
    metadata:
      labels:
        app: serving-ml-app
    spec:
      containers:
      - name: serving-ml-app
        image: tu-usuario/serving-ml-app:latest
        ports:
        - containerPort: 8000
```

- `service.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: serving-ml-app
spec:
  selector:
    app: serving-ml-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```

2. Aplicar los archivos:

```bash
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
```

## Contribuciones

¬°Las contribuciones son bienvenidas! Por favor, abre un *pull request* o issue si tienes sugerencias.

## Licencia

Este proyecto est√° licenciado bajo los t√©rminos de la licencia MIT.
